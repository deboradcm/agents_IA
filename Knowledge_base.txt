Unir-se.AI
Ferramentas de IAEventosNotíciasCertificaçõesBibliotecas PythonNomes de DomínionewslettersContacto
Search
Unir-se.AI
Unir-se.AI
Search
Inteligência artificialAuto-GPT e GPT-Engineer: um guia detalhado para os principais agentes de IA da atualidademmPublicado 1 ano atrás on 30 de agosto de 2023By Aayush Mittal
Ao comparar o ChatGPT com agentes de IA autônomos, como Auto-GPT e GPT-Engineer, surge uma diferença significativa no processo de tomada de decisão. Embora o ChatGPT exija o envolvimento humano ativo para conduzir a conversa, fornecendo orientação com base nas instruções do usuário, o processo de planejamento depende predominantemente da intervenção humana.

IA generativa modelos como transformadores são a tecnologia central de última geração, impulsionando esses agentes autônomos de IA. Esses transformadores são treinados em grandes conjuntos de dados, permitindo-lhes simular raciocínio complexo e capacidades de tomada de decisão.

Raízes de agentes autônomos de código aberto: Auto-GPT e GPT-Engineer
Muitos desses agentes autônomos de IA resultam de iniciativas de código aberto lideradas por indivíduos inovadores que transformam fluxos de trabalho convencionais. Em vez de apenas oferecer sugestões, agentes como o Auto-GPT podem realizar tarefas de forma independente, desde compras on-line até a construção de aplicativos básicos. Intérprete de código da OpenAI pretende atualizar ChatGPT desde apenas sugerir ideias até resolver ativamente problemas com essas ideias.

Tanto o Auto-GPT quanto o GPT-Engineer estão equipados com o poder do GPT 3.5 e GPT-4. Ele compreende a lógica do código, combina vários arquivos e acelera o processo de desenvolvimento.

O ponto crucial da funcionalidade do Auto-GPT está em seus agentes de IA. Esses agentes são programados para executar tarefas específicas, desde tarefas mundanas, como agendamento, até tarefas mais complexas que exigem tomada de decisões estratégicas. No entanto, estes agentes de IA operam dentro dos limites definidos pelos utilizadores. Ao controlar seu acesso por meio de APIs, os usuários podem determinar a profundidade e o escopo das ações que a IA pode realizar.

Por exemplo, se for encarregado de criar um aplicativo de bate-papo da web integrado ao ChatGPT, o Auto-GPT divide autonomamente o objetivo em etapas acionáveis, como criar um front-end HTML ou criar scripts para um back-end Python. Embora o aplicativo produza esses prompts de forma autônoma, os usuários ainda podem monitorá-los e modificá-los. Conforme mostrado pelo criador do AutoGPT @SigGravitas, é capaz de construir e executar um programa de teste baseado em Python.



Embora o diagrama abaixo descreva uma arquitetura mais geral de um agente de IA autônomo, ele oferece informações valiosas sobre os processos nos bastidores.

Arquitetura de agente de IA como Autogpt, GPT Engineer
Arquitetura de Agente Autônomo de IA

O processo é iniciado verificando a chave da API OpenAI e inicializando vários parâmetros, incluindo memória de curto prazo e conteúdo do banco de dados. Depois que os dados principais são passados ​​para o Agente, o modelo interage com o GPT3.5/GPT4 para recuperar uma resposta. Essa resposta é então transformada em um formato JSON, que o Agente interpreta para executar diversas funções, como realizar pesquisas online, ler ou gravar arquivos ou até mesmo executar código. O Auto-GPT emprega um modelo pré-treinado para armazenar essas respostas em um banco de dados, e interações futuras usam essas informações armazenadas como referência. O loop continua até que a tarefa seja considerada concluída.

Guia de configuração para Auto-GPT e GPT-Engineer
Configurar ferramentas de ponta como GPT-Engineer e Auto-GPT pode agilizar seu processo de desenvolvimento. Abaixo está um guia estruturado para ajudá-lo a instalar e configurar ambas as ferramentas.

Auto-GPT
Configurar o Auto-GPT pode parecer complexo, mas com as etapas certas, torna-se simples. Este guia aborda o procedimento de configuração do Auto-GPT e oferece insights sobre seus diversos cenários.

1. Pré-requisitos:
Ambiente Python: certifique-se de ter o Python 3.8 ou posterior instalado. Você pode obter Python em seu website oficial.
Se você planeja clonar repositórios, instale Git.
Chave da API OpenAI: Para interagir com o OpenAI, uma chave de API é necessária. Obtenha a chave da sua conta OpenAI
Abra a chave da API AI
Geração de chave de API Open AI

Opções de back-end de memória: um back-end de memória serve como mecanismo de armazenamento para o AutoGPT acessar dados essenciais para suas operações. O AutoGPT emprega recursos de armazenamento de curto e longo prazo. Pinecone, Milvus, Redise outras são algumas opções disponíveis.

2. Configurando seu espaço de trabalho:
Crie um ambiente virtual: python3 -m venv myenv
Ative o ambiente:
Mac OS ou Linux: source myenv/bin/activate
3. Instalação:
Clone o repositório Auto-GPT (certifique-se de ter o Git instalado): git clone https://github.com/Significant-Gravitas/Auto-GPT.git
Para garantir que você está trabalhando com a versão 0.2.2 do Auto-GPT, você vai querer checkout para essa versão específica: git checkout stable-0.2.2
Navegue até o repositório baixado: cd Auto-GPT
Instale as dependências necessárias: pip install -r requirements.txt
4. Configuração:
Localize .env.template no principal /Auto-GPT diretório. Duplique e renomeie para .env
Abra .env e defina sua chave de API OpenAI ao lado de OPENAI_API_KEY=
Da mesma forma, para usar Pinecone ou outros back-ends de memória, atualize o .env arquivo com sua chave e região da API Pinecone.
5. Instruções de linha de comando:
O Auto-GPT oferece um rico conjunto de argumentos de linha de comando para personalizar seu comportamento:

Uso Geral:
Exibir ajuda: python -m autogpt --help
Ajustar as configurações de IA: python -m autogpt --ai-settings <filename>
Especifique um back-end de memória: python -m autogpt --use-memory <memory-backend>
CLI AutoGPT
AutoGPT na CLI

6. Iniciando o Auto-GPT:
Assim que as configurações forem concluídas, inicie o Auto-GPT usando:

Linux ou Mac: ./run.sh start
Windows: .\run.bat
Integração Docker (abordagem de configuração recomendada)
Para aqueles que desejam conteinerizar o Auto-GPT, o Docker oferece uma abordagem simplificada. No entanto, esteja ciente de que a configuração inicial do Docker pode ser um pouco complicada. Referir-se Guia de instalação do Docker para obter assistência.

Continue seguindo as etapas abaixo para modificar a chave da API OpenAI. Certifique-se de que o Docker esteja sendo executado em segundo plano. Agora vá para o diretório principal do AutoGPT e siga os passos abaixo em seu terminal

Construa a imagem do Docker: docker build -t autogpt .
Agora execute: docker run -it --env-file=./.env -v$PWD/auto_gpt_workspace:/app/auto_gpt_workspace autogpt
Com docker-compose:

Executar: docker-compose run --build --rm auto-gpt
Para personalização complementar, você pode integrar argumentos adicionais. Por exemplo, para executar com –gpt3only e –continuous: docker-compose run --rm auto-gpt --gpt3only--continuous
Dada a ampla autonomia que o Auto-GPT possui na geração de conteúdo a partir de grandes conjuntos de dados, existe um risco potencial de acesso involuntário a fontes maliciosas da web.
Para mitigar riscos, opere o Auto-GPT em um contêiner virtual, como o Docker. Isso garante que qualquer conteúdo potencialmente prejudicial permaneça confinado no espaço virtual, mantendo seus arquivos externos e seu sistema intactos. Alternativamente, o Windows Sandbox é uma opção, embora seja redefinido após cada sessão, não conseguindo manter seu estado.

Por segurança, sempre execute o Auto-GPT em um ambiente virtual, garantindo que seu sistema permaneça isolado de saídas inesperadas.

Diante de tudo isso, ainda existe a chance de você não conseguir os resultados desejados. Usuários Auto-GPT relatados problemas recorrentes ao tentar gravar em um arquivo, muitas vezes encontrando tentativas fracassadas devido a nomes de arquivos problemáticos. Aqui está um desses erros: Auto-GPT (release 0.2.2) doesn't append the text after error "write_to_file returned: Error: File has already been updated

Várias soluções para resolver isso foram discutidas no site associado Tópico GitHub para referência.

Engenheiro GPT
Fluxo de trabalho do engenheiro GPT:

Definição de prompt: crie uma descrição detalhada do seu projeto usando linguagem natural.
Geração de Código: com base no seu prompt, o GPT-Engineer começa a trabalhar, produzindo trechos de código, funções ou até mesmo aplicativos completos.
Refinamento e Otimização: Após a geração, sempre há espaço para melhorias. Os desenvolvedores podem modificar o código gerado para atender a requisitos específicos, garantindo qualidade superior.
O processo de configuração do GPT-Engineer foi condensado em um guia fácil de seguir. Aqui está uma análise passo a passo:

1. Preparando o Meio Ambiente: Antes de começar, certifique-se de ter o diretório do projeto pronto. Abra um terminal e execute o comando abaixo

Crie um novo diretório chamado ‘website’: mkdir website
Vá para o diretório: cd website
2. Clone o Repositório:  git clone https://github.com/AntonOsika/gpt-engineer.git .

3. Navegue e instale dependências: Uma vez clonado, mude para o diretório cd gpt-engineer e instale todas as dependências necessárias make install

4. Ative o ambiente virtual: Dependendo do seu sistema operacional, ative o ambiente virtual criado.

Para macOS / Linux: source venv/bin/activate
Para Windows, é um pouco diferente devido à configuração da chave de API: set OPENAI_API_KEY=[your api key]
5. Configuração – Configuração da chave API: Para interagir com OpenAI, você precisará de uma chave API. Se você ainda não tem, cadastre-se na plataforma OpenAI e então:

Para macOS / Linux: export OPENAI_API_KEY=[your api key]
Para Windows (como mencionado anteriormente): set OPENAI_API_KEY=[your api key]
6. Inicialização do projeto e geração de código: A magia do GPT-Engineer começa com o main_prompt arquivo encontrado no projects pasta.

Se você deseja iniciar um novo projeto: cp -r projects/example/ projects/website
Aqui, substitua ‘website’ pelo nome do projeto escolhido.

Edite o main_prompt arquivo usando um editor de texto de sua escolha, anotando os requisitos do seu projeto.


Quando estiver satisfeito com o prompt, execute: gpt-engineer projects/website
Seu código gerado residirá no workspace diretório dentro da pasta do projeto.

7. Pós-geração: Embora o GPT-Engineer seja poderoso, nem sempre é perfeito. Inspecione o código gerado, faça alterações manuais, se necessário, e garanta que tudo funcione perfeitamente.

Exemplo de execução
prompt:

“Quero desenvolver um aplicativo Streamlit básico em Python que visualize os dados do usuário por meio de gráficos interativos. O aplicativo deve permitir que os usuários carreguem um arquivo CSV, selecionem o tipo de gráfico (por exemplo, barra, pizza, linha) e visualizem os dados dinamicamente. Ele pode usar bibliotecas como Pandas para manipulação de dados e Plotly para visualização.”
Configurando e executando o Engineering-GPT
Configurando e executando o GPT-Engineer

Assim como o Auto-GPT, o GPT-Engineer às vezes pode encontrar erros mesmo após uma configuração completa. No entanto, na minha terceira tentativa, acessei com sucesso a seguinte página da web streamlit. Certifique-se de revisar quaisquer erros no documento oficial Página de problemas do repositório GPT-Engineer.

Aplicativo Streamlit gerado usando Engineering-GPT
Aplicativo Streamlit gerado usando GPT-Engineer

Gargalos atuais dos agentes de IA
Despesas operacionais
Uma única tarefa executada pelo Auto-GPT pode envolver várias etapas. É importante ressaltar que cada uma dessas etapas pode ser cobrado individualmente, aumentando os custos. O Auto-GPT pode ficar preso em loops repetitivos, deixando de entregar os resultados prometidos. Tais ocorrências comprometem a sua confiabilidade e prejudicam o investimento.

Imagine querer criar um pequeno ensaio com Auto-GPT. A duração ideal do ensaio é de 8 mil tokens, mas durante o processo de criação, o modelo se aprofunda em diversas etapas intermediárias para finalizar o conteúdo. Se você estiver usando GPT-4 com comprimento de contexto de 8k, pela entrada, você será cobrado $0.03. E para a saída, o custo seria $0.06. Agora, digamos que o modelo entre em um loop imprevisto, refazendo certas partes várias vezes. Não só o processo se torna mais longo, mas cada repetição também aumenta o custo.

Para se proteger contra isso:

Definir limites de uso em Faturamento e Limites OpenAI:

Limite rígido: restringe o uso além do limite definido.
Limite suave: envia um alerta por e-mail quando o limite for atingido.
Limitações de funcionalidade
Os recursos do Auto-GPT, conforme descritos em seu código-fonte, apresentam certos limites. Suas estratégias de resolução de problemas são regidas por suas funções intrínsecas e pela acessibilidade proporcionada pela API do GPT-4. Para discussões aprofundadas e possíveis soluções alternativas, considere visitar: Discussão Auto-GPT.

Impacto da IA ​​no mercado de trabalho
A dinâmica entre a IA e os mercados de trabalho está em constante evolução e está amplamente documentada neste trabalho de pesquisa. Uma conclusão importante é que, embora o progresso tecnológico beneficie frequentemente os trabalhadores qualificados, representa riscos para aqueles que realizam tarefas rotineiras. Na verdade, os avanços tecnológicos podem substituir certas tarefas, mas simultaneamente abrir caminho para tarefas diversas e de mão-de-obra intensiva.

Agentes autônomos do mercado de trabalho de IA ultrapassam

Estima-se que 80% dos trabalhadores americanos possam descobrir que os LLMs (Modelos de Aprendizagem de Línguas) influenciam cerca de 10% das suas tarefas diárias. Esta estatística sublinha a fusão da IA ​​e das funções humanas.

O papel duplo da IA ​​na força de trabalho:

Aspectos positivos: a IA pode automatizar muitas tarefas, desde atendimento ao cliente até consultoria financeira, concedendo uma prorrogação às pequenas empresas que não têm fundos para equipes dedicadas.
Preocupações: A vantagem da automação levanta suspeitas sobre possíveis perdas de empregos, especialmente em setores onde o envolvimento humano é fundamental, como o suporte ao cliente. Junto com isso está o labirinto ético ligado ao acesso de dados confidenciais pela IA. Isto exige uma infraestrutura forte que garanta a transparência, a responsabilização e a utilização ética da IA.
Conclusão
Claramente, ferramentas como ChatGPT, Auto-GPT e GPT-Engineer estão na vanguarda da remodelação da interação entre a tecnologia e seus usuários. Com raízes em movimentos de código aberto, esses agentes de IA manifestam as possibilidades de autonomia das máquinas, agilizando tarefas desde o agendamento até o desenvolvimento de software.

À medida que avançamos para um futuro onde a IA se integra mais profundamente nas nossas rotinas diárias, torna-se fundamental um equilíbrio entre a adoção das capacidades da IA ​​e a salvaguarda dos papéis humanos. Num espectro mais amplo, a dinâmica do mercado de trabalho da IA ​​pinta uma imagem dupla de oportunidades e desafios de crescimento, exigindo uma integração consciente da ética tecnológica e da transparência.


Tópicos relacionados:AGENTES DE IAAutoGPTchat gptOpenAIENGENHARIA IMEDIATApython
A seguirChatGPT Enterprise da OpenAI se concentra em segurança, escalabilidade e personalização
Não PercaTinyML: aplicativos, limitações e uso em dispositivos IoT e Edge
mm
Aayush Mittal
Passei os últimos cinco anos mergulhando no fascinante mundo do Machine Learning e Deep Learning. Minha paixão e experiência me levaram a contribuir para mais de 50 projetos diversos de engenharia de software, com foco particular em AI/ML. Minha curiosidade contínua também me atraiu para o Processamento de Linguagem Natural, um campo que estou ansioso para explorar mais.
Você pode gostar
O recurso Claude permite estilos de escrita personalizados

Padrões de design em Python para engenheiros de IA e LLM: um guia prático
Padrões de design em Python para engenheiros de IA e LLM: um guia prático

AgentOps: Habilitando Observabilidade e Rastreabilidade para Agentes Autônomos
Agentes autônomos com AgentOps: observabilidade, rastreabilidade e muito mais para seu aplicativo de IA


Sua IA é mais poderosa do que você pensa

Tensões na parceria Microsoft OpenAI AI
A tensão entre a Microsoft e a OpenAI: o que isso significa para o futuro da IA

Inteligência Microsoft AutoGen
Microsoft AutoGen: fluxos de trabalho de IA multiagente com automação avançada

Sobre Nós
Conheça nosso equipe
Nossa Carta
Nomes de domínio .AI
Ferramentas de imprensa
Contacto
Divulgação do anunciante: A Unite.AI está comprometida com rigorosos padrões editoriais para fornecer aos nossos leitores informações e notícias precisas. Podemos receber uma compensação quando você clicar em links para produtos que analisamos.

afsqarhybgcazh-CNhrcsdanlenetfifrkadeeliwhihuisidgaitjakokulolvltlbmkmtmimnmynoplptrorugdsrskslsoessuswsvtatethtrukuruzvi
Direitos autorais © 2024 Unite.AI

Política editorial
Política de Privacidade
Termos e Condições
